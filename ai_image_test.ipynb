{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMATbEKGdKyZDuotPR1Q19J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InowaR/colab/blob/main/ai_image_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "hWPtVHzR238s"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import PIL.Image\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "# VPN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "img = PIL.Image.open('gemini.png')\n",
        "prompt = \"Что ты видишь на изображении?\"\n",
        "\n",
        "response = model.generate_content([prompt, img], stream=False)\n",
        "response.resolve()\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "N_A0Pz1zK2Jr",
        "outputId": "94137691-d002-4282-d6c8-432fa051af41"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image shows a diagram with three boxes. The left box is green and has the word \"command\" written above it. The right box is purple and has the word \"response\" written above it. The middle box is blue and has a small square inside of it. The words \"response\" and \"image\" are written below the boxes. The word \"response\" is connected to the left box and the word \"image\" is connected to the right box.\n",
            "CPU times: user 770 ms, sys: 31.3 ms, total: 801 ms\n",
            "Wall time: 7.93 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Image\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = userdata.get('GOOGLE_APPLICATION_CREDENTIALS_JSON')\n",
        "PROJECT_ID = userdata.get('PROJECT_ID')\n",
        "LOCATION = userdata.get('LOCATION')\n",
        "\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "multimodal_model = GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "g-RvEE2zKHN_"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "image = Image.load_from_file(\"gemini.png\")\n",
        "\n",
        "prompt = \"Что ты видишь на изображении?\"\n",
        "response = multimodal_model.generate_content([image, prompt], stream=False)\n",
        "\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMsdFjMTK8Iq",
        "outputId": "bffa2162-28d4-4830-fbed-17d0ffff9995"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На картинке изображена схема работы системы распознавания изображений.  \n",
            "Зеленый прямоугольник — изображение,  \n",
            "Синий —  модель распознавания, \n",
            "Фиолетовый — текст,  \n",
            "Серая линия —  путь передачи данных.  \n",
            "Описание:\n",
            "1. Системе передается изображение. \n",
            "2. Системе передается команда, вероятно, для описания изображения.\n",
            "3.  Модель распознает изображение, \n",
            "4. Система выдает ответ.\n",
            "CPU times: user 23.2 ms, sys: 7.84 ms, total: 31.1 ms\n",
            "Wall time: 2.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# VPN"
      ],
      "metadata": {
        "id": "3wRBx6juFtou"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%%bash\n",
        "echo '{\n",
        "  \"contents\":[\n",
        "    {\n",
        "      \"parts\":[\n",
        "        {\"text\": \"Что ты видишь на изображении?\"},\n",
        "        {\n",
        "          \"inline_data\": {\n",
        "            \"mime_type\":\"image/jpeg\",\n",
        "            \"data\": \"'$(base64 -w0 gemini.png)'\"\n",
        "          }\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}' > request.json\n",
        "\n",
        "curl https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GOOGLE_API_KEY} \\\n",
        "        -H 'Content-Type: application/json' \\\n",
        "        -d @request.json 2> /dev/null | grep \"text\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_7IitIMFzBq",
        "outputId": "1bdf5e0c-5d44-4047-ca6c-726ccf3ef92e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            \"text\": \"The image is a diagram showing the relationship between a command, a response, an image, and a text-based response. \\n\\nThe diagram shows a rectangle labeled \\\"command\\\" with an arrow pointing to a rectangle labeled \\\"response\\\" that contains the word \\\"response\\\" inside.  A second arrow points from the \\\"response\\\" rectangle to another rectangle labeled \\\"image.\\\"  There is a third arrow pointing from the \\\"image\\\" rectangle to a rectangle labeled \\\"response.\\\"  There is a final arrow pointing from the \\\"command\\\" rectangle to a rectangle labeled \\\"response.\\\"\\n\\nThe diagram shows how a command can be used to generate a response, which in turn can be used to generate an image. The image can then be used to generate a text-based response. The command can also be used to generate a text-based response directly.\"\n",
            "CPU times: user 20.1 ms, sys: 4.09 ms, total: 24.2 ms\n",
            "Wall time: 2.45 s\n"
          ]
        }
      ]
    }
  ]
}