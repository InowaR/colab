{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMls6QmfqVEOXC2hcexLBbf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InowaR/colab/blob/main/simple_sigmoid_xor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def convert_to_bit_array(double_array):\n",
        "    bit_array = []\n",
        "    for sublist in double_array:\n",
        "        binary_sublist = [int(bit) for num in sublist for bit in format(num, '08b')]\n",
        "        bit_array.append(binary_sublist)\n",
        "    return bit_array\n",
        "\n",
        "\n",
        "X = [[14, 2, 80, 2, 16, 132, 115, 14],\n",
        "     [3, 36, 25, 31, 4, 54, 45, 13],\n",
        "     [11, 255, 11, 102, 54, 5, 255, 12],\n",
        "     [171, 68, 2, 130, 6, 148, 35, 11]]\n",
        "\n",
        "\n",
        "y = [[1, 0, 0, 0],\n",
        "     [0, 1, 0, 1],\n",
        "     [1, 0, 0, 0],\n",
        "     [0, 1, 1, 0]]\n",
        "\n",
        "X = np.array(convert_to_bit_array(X))\n",
        "print(X)"
      ],
      "metadata": {
        "id": "Xzhd2PBtoIzO",
        "outputId": "1384ed30-83c7-4b6e-fafa-c6955b032623",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
            "  0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0]\n",
            " [0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0\n",
            "  0 1 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1]\n",
            " [0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1\n",
            "  0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0]\n",
            " [1 0 1 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
            "  0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def func1(epochs, X, y):\n",
        "    input_neurons = 64\n",
        "    hidden_neurons = 4\n",
        "    output_neurons = 4\n",
        "    weights_input_hidden = np.random.rand(input_neurons, hidden_neurons)\n",
        "    weights_hidden_output = np.random.rand(hidden_neurons, output_neurons)\n",
        "    for i in range(epochs):\n",
        "        hidden_layer_input = np.dot(X, weights_input_hidden)\n",
        "        hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "        output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "        output = sigmoid(output_layer_input)\n",
        "        error = y - output\n",
        "        output_gradient = output * (1 - output) * error\n",
        "        error_hidden = output_gradient.dot(weights_hidden_output.T)\n",
        "        hidden_gradient = hidden_layer_output * (1 - hidden_layer_output) * error_hidden\n",
        "        weights_hidden_output += hidden_layer_output.T.dot(output_gradient)\n",
        "        weights_input_hidden += X.T.dot(hidden_gradient)\n",
        "    return weights_input_hidden, weights_hidden_output\n",
        "\n",
        "\n",
        "def test1(weights_input_hidden, weights_hidden_output, X):\n",
        "    hidden_layer_input = np.dot(X, weights_input_hidden)\n",
        "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "    output = sigmoid(output_layer_input)\n",
        "    return output\n",
        "\n",
        "\n",
        "def find_best_coefficients1(X, y):\n",
        "    best_error = np.inf\n",
        "    global best_epoch\n",
        "    for epoch in range(1000, 1100):\n",
        "            weights_input_hidden, weights_hidden_output = func1(epoch, X, y)\n",
        "            training_error = np.sum(np.square(y - test1(weights_input_hidden, weights_hidden_output, X)))\n",
        "            if training_error < best_error:\n",
        "                best_error = training_error\n",
        "                best_epoch = epoch\n",
        "    return best_epoch\n",
        "\n",
        "\n",
        "epochs = find_best_coefficients1(X, y)\n",
        "print(\"Best epoch:\", epochs)\n",
        "\n",
        "weights_input_hidden, weights_hidden_output = func1(epochs, X, y)\n",
        "\n",
        "print(weights_input_hidden)\n",
        "print(weights_hidden_output)\n",
        "\n",
        "test_error = np.sum(np.square(y - test1(weights_input_hidden, weights_hidden_output, X)))\n",
        "print(\"Test error:\", \"{:.5f}\".format(test_error))\n",
        "\n",
        "print(\"Predictions on test data:\")\n",
        "print(test1(weights_input_hidden, weights_hidden_output, np.array([X[0]])))"
      ],
      "metadata": {
        "id": "sgt_ZJmPPDw3",
        "outputId": "dff32c2a-8315-4abf-d78c-32dc40aa0216",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best epoch: 1026\n",
            "[[ 0.77474465 -0.00276937  0.82761504  0.08793457]\n",
            " [ 0.31971196  0.51414791  0.73488002  0.39568391]\n",
            " [ 0.26329146  0.40742802  0.45691911  0.75546103]\n",
            " [ 0.55133225  0.57939913  0.61447668  0.99338848]\n",
            " [ 0.78191723  0.23407072  0.06421532  0.50952297]\n",
            " [ 0.35762139  0.58464597  1.01185599  0.16311933]\n",
            " [ 0.6943679   0.33163969  0.31391591  0.42519947]\n",
            " [ 0.26345229  0.04361985  0.5484533   0.91580786]\n",
            " [ 0.1847064   0.43911729  0.7397977   0.62683847]\n",
            " [ 0.78845523  0.69300556  0.09140256  0.83077649]\n",
            " [ 0.07276807  0.97259101  0.29548885  0.8158802 ]\n",
            " [ 0.4140043   0.52720916  0.63708752  0.48271353]\n",
            " [ 0.78760357  0.74331605  0.83968636  0.48255919]\n",
            " [ 0.52744914  0.86921328  0.84030644  0.83723571]\n",
            " [ 0.51141009  0.22924112  0.16814274  0.0085552 ]\n",
            " [ 0.81368591  0.25454833  0.64040019  0.09388282]\n",
            " [ 0.39764397  0.97670497  0.18341487  0.86020386]\n",
            " [ 0.19431845  0.40684981  0.50693639  0.79340664]\n",
            " [ 0.57660265  0.26049194  0.25746221  0.39766543]\n",
            " [ 0.7591264   0.15256069  0.5832396   0.7482566 ]\n",
            " [ 0.40523496  0.41564016  0.95473906  0.89376207]\n",
            " [ 0.92061591  0.93282143  0.65045558  0.02504287]\n",
            " [ 0.48567304  0.3708421   0.1457744   0.02567458]\n",
            " [ 0.30298529  0.38157569  0.90759727  0.2330006 ]\n",
            " [ 0.96030939  0.56605399  0.11447868  0.57217247]\n",
            " [ 0.32067253  0.59496447  0.89753561  0.99139218]\n",
            " [ 0.26986546  0.69313311  0.55077234  0.02132428]\n",
            " [ 0.45782506  0.95806948  0.67022374  0.17607408]\n",
            " [ 0.26096624  0.89770936  0.16347559  0.93985002]\n",
            " [ 0.06266724  0.24268027  0.70703577  0.00108452]\n",
            " [ 0.58881968  0.57590777  0.07415751  0.95888197]\n",
            " [ 0.80970375  0.71851892  0.51583873  0.77932627]\n",
            " [ 0.16185494  0.19793577  0.69147628  0.33512753]\n",
            " [ 0.16588905  0.6010406   0.13751364  0.48478761]\n",
            " [ 0.34332945  0.98714313  0.6968957   0.61927868]\n",
            " [ 0.12198623  0.74066845  0.26212795  0.69501896]\n",
            " [ 0.4202583   0.32366739  0.51700198  0.6698245 ]\n",
            " [ 0.42491297  0.38839323  0.49329641  0.49000087]\n",
            " [ 0.67571808  0.18162655  0.11868766  0.45756865]\n",
            " [ 0.73327146  0.1324518   0.34320286  0.09031495]\n",
            " [ 0.70675849  0.8980458   0.72999186  0.33924427]\n",
            " [ 0.45186836  0.66171009  0.74664282  0.10645247]\n",
            " [ 0.93319079  0.82086455  0.55002575  0.98708701]\n",
            " [ 0.24257922  0.22097288  0.89314271  0.35264093]\n",
            " [ 0.54479312  0.66312685  0.79026884  0.9480272 ]\n",
            " [ 0.06539496  0.99059283  0.23362315  0.38575305]\n",
            " [ 0.71327332  0.0422768   0.83761746  0.46241904]\n",
            " [ 0.79057994  0.1189547   0.879436    0.87953943]\n",
            " [ 0.57455207  0.31977926  0.86543119  0.32273755]\n",
            " [ 0.05453742  0.56661443  0.74657661  0.41415442]\n",
            " [ 0.97632806  0.38613831  0.29298468  0.7889468 ]\n",
            " [ 0.70926344  0.74159114  0.34125964  0.76452858]\n",
            " [ 0.52942755  0.61795873  0.89537403  0.8716676 ]\n",
            " [ 0.06011392  0.41274236  0.25813483  0.63512511]\n",
            " [ 0.39415643  0.4976304   0.32960415  0.31032313]\n",
            " [ 0.65219903  0.58813435  0.77864341  0.94650129]\n",
            " [ 0.28536345  0.44866078  0.97068019  0.06376123]\n",
            " [ 0.35395721  0.7194326   0.09064907  0.87282191]\n",
            " [ 0.68808007  0.06849268  0.44460093  0.90198934]\n",
            " [ 0.23803865  0.53272161  0.15295033  0.38177392]\n",
            " [ 0.08612462  0.23652075  0.5628727   0.33502252]\n",
            " [ 0.06349439  0.11222566  0.70753267  0.13304332]\n",
            " [ 0.63182267  0.28988384  0.12352339  0.07007515]\n",
            " [ 0.90251725  0.90635826  0.40596047  0.02056268]]\n",
            "[[-0.45305801  0.28330478 -0.67933135  0.04493651]\n",
            " [ 0.30753638 -0.47861624 -0.18119582 -0.33024984]\n",
            " [ 0.39018361 -0.17436015  0.09702759 -0.46134656]\n",
            " [-0.24470253  0.36972883 -0.33519925 -0.35202581]]\n",
            "Test error: 3.50005\n",
            "Predictions on test data:\n",
            "[[0.49997255 0.50002364 0.25002273 0.25004047]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def func2(A, B, C, D, E, X, y):\n",
        "    input_neurons = 64\n",
        "    hidden_neurons = 4\n",
        "    output_neurons = 4\n",
        "    weights_input_hidden = A * np.random.rand(input_neurons, hidden_neurons) + B\n",
        "    weights_hidden_output = C * np.random.rand(hidden_neurons, output_neurons) + D\n",
        "    for i in range(epochs):\n",
        "        hidden_layer_input = np.dot(X, weights_input_hidden)\n",
        "        hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "        output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "        output = sigmoid(output_layer_input)\n",
        "        error = y - output\n",
        "        output_gradient = output * (1 - output) * error\n",
        "        error_hidden = output_gradient.dot(weights_hidden_output.T)\n",
        "        hidden_gradient = hidden_layer_output * (1 - hidden_layer_output) * error_hidden\n",
        "        weights_hidden_output += E * hidden_layer_output.T.dot(output_gradient)\n",
        "        weights_input_hidden += E * X.T.dot(hidden_gradient)\n",
        "    return weights_input_hidden, weights_hidden_output\n",
        "\n",
        "\n",
        "def test2(weights_input_hidden, weights_hidden_output, X):\n",
        "    hidden_layer_input = np.dot(X, weights_input_hidden)\n",
        "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "    output = sigmoid(output_layer_input)\n",
        "    return output\n",
        "\n",
        "\n",
        "def find_best_coefficients2(X, y):\n",
        "    best_error = np.inf\n",
        "    global best_A, best_B, best_C, best_D, best_E\n",
        "    for A in range(-1, 1):\n",
        "        for B in range(-1, 1):\n",
        "            for C in range(-1, 1):\n",
        "                for D in range(-1, 1):\n",
        "                    for E in range(1, 10):\n",
        "                        weights_input_hidden, weights_hidden_output = func2(A, B, C, D, E, X, y)\n",
        "                        training_error = np.sum(np.square(y - test2(weights_input_hidden, weights_hidden_output, X)))\n",
        "                        if training_error < best_error:\n",
        "                            best_error = training_error\n",
        "                            best_A, best_B, best_C, best_D, best_E = A, B, C, D, E\n",
        "    return best_A, best_B, best_C, best_D, best_E\n",
        "\n",
        "\n",
        "A, B, C, D, E = find_best_coefficients2(X, y)\n",
        "print(\"Best coefficients:\", A, B, C, D, E)\n",
        "\n",
        "weights_input_hidden, weights_hidden_output = func2(A, B, C, D, E, X, y)\n",
        "\n",
        "print(weights_input_hidden)\n",
        "print(weights_hidden_output)\n",
        "\n",
        "test_error = np.sum(np.square(y - test2(weights_input_hidden, weights_hidden_output, X)))\n",
        "print(\"Test error:\", \"{:.5f}\".format(test_error))\n",
        "\n",
        "print(\"Predictions on test data:\")\n",
        "print(test1(weights_input_hidden, weights_hidden_output, np.array([X[0]])))"
      ],
      "metadata": {
        "id": "rsdcsY-Dd3BR",
        "outputId": "f34767aa-4d80-4958-aa5e-f57ccaa400c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best coefficients: 0 0 -1 0 7\n",
            "[[-0.32256005  0.73066405 -0.60075618 -0.42794735]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.32256005  0.73066405 -0.60075618 -0.42794735]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.60442233  0.25448778  0.39510117  0.34951912]\n",
            " [-0.1041976  -0.37386042  0.50656064  0.41059331]\n",
            " [-0.06106235 -0.14177054 -0.14256431 -0.10302674]\n",
            " [ 0.04313525  0.23208987 -0.64912495 -0.51362005]\n",
            " [-0.17766467 -0.10231586  0.48929672  0.36687316]\n",
            " [-0.50022473  0.62834819 -0.11145947 -0.06107419]\n",
            " [ 0.3656953  -0.49857418 -0.04836877 -0.08567269]\n",
            " [-0.17766467 -0.10231586  0.48929672  0.36687316]\n",
            " [-0.17766467 -0.10231586  0.48929672  0.36687316]\n",
            " [ 0.04313525  0.23208987 -0.64912495 -0.51362005]\n",
            " [-0.28186228 -0.47617627  0.99585736  0.77746648]\n",
            " [-0.17766467 -0.10231586  0.48929672  0.36687316]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.1041976  -0.37386042  0.50656064  0.41059331]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.43916238 -0.77011874 -0.03110485 -0.04195255]\n",
            " [ 0.3656953  -0.49857418 -0.04836877 -0.08567269]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.50022473  0.62834819 -0.11145947 -0.06107419]\n",
            " [ 0.3656953  -0.49857418 -0.04836877 -0.08567269]\n",
            " [-0.32256005  0.73066405 -0.60075618 -0.42794735]\n",
            " [-0.17766467 -0.10231586  0.48929672  0.36687316]\n",
            " [-0.17766467 -0.10231586  0.48929672  0.36687316]\n",
            " [ 0.54335998 -0.39625832 -0.53766549 -0.45254586]\n",
            " [ 0.54335998 -0.39625832 -0.53766549 -0.45254586]\n",
            " [ 0.3656953  -0.49857418 -0.04836877 -0.08567269]\n",
            " [-0.06106235 -0.14177054 -0.14256431 -0.10302674]\n",
            " [ 0.54335998 -0.39625832 -0.53766549 -0.45254586]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.17766467 -0.10231586  0.48929672  0.36687316]\n",
            " [-0.28186228 -0.47617627  0.99585736  0.77746648]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.04313525  0.23208987 -0.64912495 -0.51362005]\n",
            " [-0.50022473  0.62834819 -0.11145947 -0.06107419]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.42675765  0.35680363 -0.09419554 -0.01735404]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.54335998 -0.39625832 -0.53766549 -0.45254586]\n",
            " [ 0.22079993  0.33440573 -1.13842167 -0.88049321]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.06106235 -0.14177054 -0.14256431 -0.10302674]\n",
            " [ 0.54335998 -0.39625832 -0.53766549 -0.45254586]\n",
            " [-0.17766467 -0.10231586  0.48929672  0.36687316]\n",
            " [-0.17766467 -0.10231586  0.48929672  0.36687316]\n",
            " [-0.28186228 -0.47617627  0.99585736  0.77746648]\n",
            " [-0.06106235 -0.14177054 -0.14256431 -0.10302674]\n",
            " [-0.28186228 -0.47617627  0.99585736  0.77746648]\n",
            " [ 0.3656953  -0.49857418 -0.04836877 -0.08567269]\n",
            " [ 0.3656953  -0.49857418 -0.04836877 -0.08567269]\n",
            " [-0.60442233  0.25448778  0.39510117  0.34951912]\n",
            " [-0.06106235 -0.14177054 -0.14256431 -0.10302674]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.06106235 -0.14177054 -0.14256431 -0.10302674]\n",
            " [ 0.2614977  -0.87243459  0.45819187  0.32492062]\n",
            " [-0.42675765  0.35680363 -0.09419554 -0.01735404]\n",
            " [ 0.22079993  0.33440573 -1.13842167 -0.88049321]]\n",
            "[[-4.76324972  4.76384157 -4.79867017  4.76578645]\n",
            " [-4.72713796  4.72875738  4.85454124 -4.81940167]\n",
            " [ 3.92381651 -3.76753497 -3.48800084 -3.11138518]\n",
            " [ 2.02590725 -2.18856699 -1.792102   -2.63666425]]\n",
            "Test error: 0.00070\n",
            "Predictions on test data:\n",
            "[[0.99629775 0.00368407 0.00470043 0.00377871]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_input_hidden = np.array([[-0.32256005 ,  0.73066405, -0.60075618, -0.42794735],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [-0.32256005,  0.73066405, -0.60075618, -0.42794735],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [-0.60442233,  0.25448778,  0.39510117,  0.34951912],\n",
        "                                  [-0.1041976 , -0.37386042,  0.50656064,  0.41059331],\n",
        "                                  [-0.06106235, -0.14177054, -0.14256431, -0.10302674],\n",
        "                                  [ 0.04313525,  0.23208987, -0.64912495, -0.51362005],\n",
        "                                  [-0.17766467, -0.10231586,  0.48929672,  0.36687316],\n",
        "                                  [-0.50022473,  0.62834819, -0.11145947, -0.06107419],\n",
        "                                  [ 0.3656953 , -0.49857418, -0.04836877, -0.08567269],\n",
        "                                  [-0.17766467, -0.10231586,  0.48929672,  0.36687316],\n",
        "                                  [-0.17766467, -0.10231586,  0.48929672,  0.36687316],\n",
        "                                  [ 0.04313525,  0.23208987, -0.64912495, -0.51362005],\n",
        "                                  [-0.28186228, -0.47617627,  0.99585736,  0.77746648],\n",
        "                                  [-0.17766467, -0.10231586,  0.48929672,  0.36687316],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [-0.1041976 , -0.37386042,  0.50656064,  0.41059331],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [ 0.43916238, -0.77011874, -0.03110485, -0.04195255],\n",
        "                                  [ 0.3656953 , -0.49857418, -0.04836877, -0.08567269],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [-0.50022473,  0.62834819, -0.11145947, -0.06107419],\n",
        "                                  [ 0.3656953 , -0.49857418, -0.04836877, -0.08567269],\n",
        "                                  [-0.32256005,  0.73066405, -0.60075618, -0.42794735],\n",
        "                                  [-0.17766467, -0.10231586,  0.48929672,  0.36687316],\n",
        "                                  [-0.17766467, -0.10231586,  0.48929672,  0.36687316],\n",
        "                                  [ 0.54335998, -0.39625832, -0.53766549, -0.45254586],\n",
        "                                  [ 0.54335998, -0.39625832, -0.53766549, -0.45254586],\n",
        "                                  [ 0.3656953 , -0.49857418, -0.04836877, -0.08567269],\n",
        "                                  [-0.06106235, -0.14177054, -0.14256431, -0.10302674],\n",
        "                                  [ 0.54335998, -0.39625832, -0.53766549, -0.45254586],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [-0.17766467, -0.10231586,  0.48929672,  0.36687316],\n",
        "                                  [-0.28186228, -0.47617627,  0.99585736,  0.77746648],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [ 0.04313525,  0.23208987, -0.64912495, -0.51362005],\n",
        "                                  [-0.50022473,  0.62834819, -0.11145947, -0.06107419],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [-0.42675765,  0.35680363, -0.09419554, -0.01735404],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [ 0.54335998, -0.39625832, -0.53766549, -0.45254586],\n",
        "                                  [ 0.22079993,  0.33440573, -1.13842167, -0.88049321],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [-0.06106235, -0.14177054, -0.14256431, -0.10302674],\n",
        "                                  [ 0.54335998, -0.39625832, -0.53766549, -0.45254586],\n",
        "                                  [-0.17766467, -0.10231586,  0.48929672,  0.36687316],\n",
        "                                  [-0.17766467, -0.10231586,  0.48929672,  0.36687316],\n",
        "                                  [-0.28186228, -0.47617627,  0.99585736,  0.77746648],\n",
        "                                  [-0.06106235, -0.14177054, -0.14256431, -0.10302674],\n",
        "                                  [-0.28186228, -0.47617627,  0.99585736,  0.77746648],\n",
        "                                  [ 0.3656953 , -0.49857418, -0.04836877, -0.08567269],\n",
        "                                  [ 0.3656953 , -0.49857418, -0.04836877, -0.08567269],\n",
        "                                  [-0.60442233,  0.25448778,  0.39510117,  0.34951912],\n",
        "                                  [-0.06106235, -0.14177054, -0.14256431, -0.10302674],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
        "                                  [-0.06106235, -0.14177054, -0.14256431, -0.10302674],\n",
        "                                  [ 0.2614977 , -0.87243459,  0.45819187,  0.32492062],\n",
        "                                  [-0.42675765,  0.35680363, -0.09419554, -0.01735404],\n",
        "                                  [ 0.22079993,  0.33440573, -1.13842167, -0.88049321]])\n",
        "\n",
        "\n",
        "\n",
        "weights_hidden_output = np.array([[-4.76324972,  4.76384157, -4.79867017,  4.76578645],\n",
        "                                  [-4.72713796,  4.72875738,  4.85454124, -4.81940167],\n",
        "                                  [ 3.92381651, -3.76753497, -3.48800084, -3.11138518],\n",
        "                                  [ 2.02590725, -2.18856699, -1.792102,   -2.63666425]])\n",
        "\n",
        "\n",
        "def simple_func_test(weights_input_hidden, weights_hidden_output, X):\n",
        "    hidden_layer_input = np.dot(X, weights_input_hidden)\n",
        "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "    output = sigmoid(output_layer_input)\n",
        "    return output\n",
        "\n",
        "print(\"Predictions on test data:\")\n",
        "print(test1(weights_input_hidden, weights_hidden_output, np.array([X[0]])))\n",
        "print(test1(weights_input_hidden, weights_hidden_output, np.array([X[1]])))\n",
        "print(test1(weights_input_hidden, weights_hidden_output, np.array([X[2]])))"
      ],
      "metadata": {
        "id": "H2zb2hA8NoYL",
        "outputId": "868c9438-6002-46d6-f681-71bf5c148bfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions on test data:\n",
            "[[0.99629775 0.00368407 0.00470043 0.00377871]]\n",
            "[[0.00853967 0.99146374 0.00834107 0.9912943 ]]\n",
            "[[0.99660887 0.00337428 0.00456985 0.00373197]]\n"
          ]
        }
      ]
    }
  ]
}