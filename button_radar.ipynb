{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEGgCeNxVhKlguUPwD50ef",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InowaR/colab/blob/main/button_radar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Flatten, Dense\n",
        "\n",
        "\n",
        "def select_random_subarrays(X, Y, num_samples=20):\n",
        "    if len(X) != len(Y):\n",
        "        raise ValueError(\"The X and Y dimensions must match\")\n",
        "    X_selected = []\n",
        "    Y_selected = []\n",
        "    selected_count = 0\n",
        "    selected_indices = []\n",
        "    while selected_count < num_samples:\n",
        "        random_index = np.random.randint(0, len(X))\n",
        "        if random_index not in selected_indices:\n",
        "            X_selected.append(X[random_index])\n",
        "            Y_selected.append(Y[random_index])\n",
        "            selected_indices.append(random_index)\n",
        "            selected_count += 1\n",
        "    return X_selected, Y_selected\n",
        "\n",
        "def normalize_array_2d(array, max_value=800, new_max_value=255):\n",
        "    if not isinstance(array, np.ndarray):\n",
        "        raise TypeError(\"Input array must be a NumPy array.\")\n",
        "    if array.ndim != 2:\n",
        "        raise ValueError(\"Input array must be a two-dimensional array.\")\n",
        "    if np.min(array) < 0:\n",
        "        raise ValueError(\"Input array cannot contain negative values.\")\n",
        "    normalized_array = array / max_value\n",
        "    rescaled_array = normalized_array * new_max_value\n",
        "    return rescaled_array\n",
        "\n",
        "def convert_to_bit_array(double_array):\n",
        "    bit_array = []\n",
        "    for sublist in double_array:\n",
        "        binary_sublist = [int(bit) for num in sublist for bit in format(int(num), '08b')]\n",
        "        bit_array.append(binary_sublist)\n",
        "    return bit_array"
      ],
      "metadata": {
        "id": "XjWVlcLIIoBV"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uqaPIeKDF0d",
        "outputId": "bcfe9a11-ad22-42c5-b0e3-213e8517059a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[125. 275. 190. 410.]\n",
            " [100.  80. 385. 215.]\n",
            " [125. 275. 185. 415.]\n",
            " [125.  95. 125. 475.]\n",
            " [160.  80. 485. 115.]\n",
            " [295. 265. 310. 160.]\n",
            " [240. 160.  40. 400.]\n",
            " [160.  80. 485. 115.]\n",
            " [410. 150. 100. 290.]\n",
            " [125.  95. 125. 475.]\n",
            " [205. 195. 200.  50.]\n",
            " [360. 200. 310.  40.]\n",
            " [160. 400. 310. 290.]\n",
            " [220. 180. 200.  50.]\n",
            " [160.  80. 485. 115.]\n",
            " [ 75. 485. 280. 150.]\n",
            " [160.  80. 485. 115.]\n",
            " [160.  80. 485. 115.]\n",
            " [480.  80. 310. 290.]\n",
            " [160.  80. 485. 115.]]\n",
            "[[ 39.84375  87.65625  60.5625  130.6875 ]\n",
            " [ 31.875    25.5     122.71875  68.53125]\n",
            " [ 39.84375  87.65625  58.96875 132.28125]\n",
            " [ 39.84375  30.28125  39.84375 151.40625]\n",
            " [ 51.       25.5     154.59375  36.65625]\n",
            " [ 94.03125  84.46875  98.8125   51.     ]\n",
            " [ 76.5      51.       12.75    127.5    ]\n",
            " [ 51.       25.5     154.59375  36.65625]\n",
            " [130.6875   47.8125   31.875    92.4375 ]\n",
            " [ 39.84375  30.28125  39.84375 151.40625]\n",
            " [ 65.34375  62.15625  63.75     15.9375 ]\n",
            " [114.75     63.75     98.8125   12.75   ]\n",
            " [ 51.      127.5      98.8125   92.4375 ]\n",
            " [ 70.125    57.375    63.75     15.9375 ]\n",
            " [ 51.       25.5     154.59375  36.65625]\n",
            " [ 23.90625 154.59375  89.25     47.8125 ]\n",
            " [ 51.       25.5     154.59375  36.65625]\n",
            " [ 51.       25.5     154.59375  36.65625]\n",
            " [153.       25.5      98.8125   92.4375 ]\n",
            " [ 51.       25.5     154.59375  36.65625]]\n",
            "[[0 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0]\n",
            " [0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 0]\n",
            " [0 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0]\n",
            " [0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1]\n",
            " [0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0]\n",
            " [0 1 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1]\n",
            " [0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1]\n",
            " [0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0]\n",
            " [1 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 0 0]\n",
            " [0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1]\n",
            " [0 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0]\n",
            " [0 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0]\n",
            " [0 1 0 0 0 1 1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1]\n",
            " [0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0]\n",
            " [0 0 0 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1]\n",
            " [0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0]\n",
            " [0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0]\n",
            " [1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0]\n",
            " [0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0]]\n",
            "[[0 0 0 0]\n",
            " [0 0 0 1]\n",
            " [0 0 0 1]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 1]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]]\n",
            "20\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "with open('radar_array_train.txt', 'rb') as radar:\n",
        "  x_train = pickle.load(radar)\n",
        "\n",
        "with open('button_array_train.txt', 'rb') as button:\n",
        "  y_train = pickle.load(button)\n",
        "\n",
        "x_selected, y_selected = select_random_subarrays(x_train, y_train)\n",
        "x_train = np.array(x_selected)\n",
        "y_train = np.array(y_selected)\n",
        "x_train_normalized = normalize_array_2d(x_train, max_value=800, new_max_value=255)\n",
        "x_train_bit_array = convert_to_bit_array(x_train_normalized)\n",
        "x_train_bit_array = np.array(x_train_bit_array)\n",
        "print(x_train)\n",
        "print(x_train_normalized)\n",
        "print(x_train_bit_array)\n",
        "print(y_train)\n",
        "print(len(x_train))\n",
        "print(len(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = x_train_bit_array\n",
        "y = y_train\n",
        "\n",
        "start = y.shape[1]\n",
        "stop = X.shape[1]\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def func1(num_hidden_layer, epochs, X, y):\n",
        "    input_neurons = X.shape[1]\n",
        "    hidden_neurons = num_hidden_layer\n",
        "    output_neurons = y.shape[1]\n",
        "    weights_input_hidden = np.random.rand(input_neurons, hidden_neurons)\n",
        "    weights_hidden_output = np.random.rand(hidden_neurons, output_neurons)\n",
        "    for i in range(epochs):\n",
        "        hidden_layer_input = np.dot(X, weights_input_hidden)\n",
        "        hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "        output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "        output = sigmoid(output_layer_input)\n",
        "        error = y - output\n",
        "        output_gradient = output * (1 - output) * error\n",
        "        error_hidden = output_gradient.dot(weights_hidden_output.T)\n",
        "        hidden_gradient = hidden_layer_output * (1 - hidden_layer_output) * error_hidden\n",
        "        weights_hidden_output += hidden_layer_output.T.dot(output_gradient)\n",
        "        weights_input_hidden += X.T.dot(hidden_gradient)\n",
        "    return weights_input_hidden, weights_hidden_output\n",
        "\n",
        "\n",
        "def test1(weights_input_hidden, weights_hidden_output, X):\n",
        "    hidden_layer_input = np.dot(X, weights_input_hidden)\n",
        "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "    output = sigmoid(output_layer_input)\n",
        "    return output\n",
        "\n",
        "\n",
        "def find_best_coefficients1(X, y):\n",
        "    best_error = np.inf\n",
        "    global best_num_hidden_layer, best_epoch\n",
        "    for num_hidden_layer in range(start+(stop//3), stop//2):\n",
        "        for epoch in range(2000, 2001):\n",
        "            weights_input_hidden, weights_hidden_output = func1(num_hidden_layer, epoch, X, y)\n",
        "            training_error = np.sum(np.square(y - test1(weights_input_hidden, weights_hidden_output, X)))\n",
        "            if training_error < best_error:\n",
        "                best_error = training_error\n",
        "                best_num_hidden_layer, best_epoch  =  num_hidden_layer, epoch\n",
        "    return best_num_hidden_layer, best_epoch\n",
        "\n",
        "\n",
        "num_hidden_layer, epochs = find_best_coefficients1(X, y)\n",
        "print(\"Best num_hidden_layer:\", num_hidden_layer)\n",
        "print(\"Best epoch:\", epochs)\n",
        "\n",
        "weights_input_hidden, weights_hidden_output = func1(num_hidden_layer, epochs, X, y)\n",
        "\n",
        "# print(weights_input_hidden)\n",
        "# print(weights_hidden_output)\n",
        "\n",
        "test_error = np.sum(np.square(y - test1(weights_input_hidden, weights_hidden_output, X)))\n",
        "print(\"Test error:\", \"{:.5f}\".format(test_error))\n",
        "\n",
        "print(\"Predictions on test data:\")\n",
        "print(test1(weights_input_hidden, weights_hidden_output, np.array([X[0]])))"
      ],
      "metadata": {
        "id": "9fGiE0WQ-FfR",
        "outputId": "1dafec73-343a-47a2-cdf3-39ee9895aadd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best num_hidden_layer: 14\n",
            "Best epoch: 2000\n",
            "Test error: 10.00002\n",
            "Predictions on test data:\n",
            "[[1.27427200e-04 9.63581239e-09 9.46806418e-04 1.07769450e-08]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def func2(A, B, C, D, E, X, y):\n",
        "    input_neurons = X.shape[1]\n",
        "    hidden_neurons = num_hidden_layer\n",
        "    output_neurons = y.shape[1]\n",
        "    weights_input_hidden = A * np.random.rand(input_neurons, hidden_neurons) + B\n",
        "    weights_hidden_output = C * np.random.rand(hidden_neurons, output_neurons) + D\n",
        "    for i in range(epochs):\n",
        "        hidden_layer_input = np.dot(X, weights_input_hidden)\n",
        "        hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "        output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "        output = sigmoid(output_layer_input)\n",
        "        error = y - output\n",
        "        output_gradient = output * (1 - output) * error\n",
        "        error_hidden = output_gradient.dot(weights_hidden_output.T)\n",
        "        hidden_gradient = hidden_layer_output * (1 - hidden_layer_output) * error_hidden\n",
        "        weights_hidden_output += E * hidden_layer_output.T.dot(output_gradient)\n",
        "        weights_input_hidden += E * X.T.dot(hidden_gradient)\n",
        "    return weights_input_hidden, weights_hidden_output\n",
        "\n",
        "\n",
        "def test2(weights_input_hidden, weights_hidden_output, X):\n",
        "    hidden_layer_input = np.dot(X, weights_input_hidden)\n",
        "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "    output = sigmoid(output_layer_input)\n",
        "    return output\n",
        "\n",
        "\n",
        "def find_best_coefficients2(X, y):\n",
        "    best_error = np.inf\n",
        "    global best_A, best_B, best_C, best_D, best_E\n",
        "    for A in range(-1, 1):\n",
        "        for B in range(-1, 1):\n",
        "            for C in range(-1, 1):\n",
        "                for D in range(-1, 1):\n",
        "                    for E in range(-1, 2):\n",
        "                        weights_input_hidden, weights_hidden_output = func2(A, B, C, D, E, X, y)\n",
        "                        training_error = np.sum(np.square(y - test2(weights_input_hidden, weights_hidden_output, X)))\n",
        "                        if training_error < best_error:\n",
        "                            best_error = training_error\n",
        "                            best_A, best_B, best_C, best_D, best_E = A, B, C, D, E\n",
        "    return best_A, best_B, best_C, best_D, best_E\n",
        "\n",
        "\n",
        "A, B, C, D, E = find_best_coefficients2(X, y)\n",
        "print(\"Best coefficients:\", A, B, C, D, E)\n",
        "\n",
        "weights_input_hidden, weights_hidden_output = func2(A, B, C, D, E, X, y)\n",
        "\n",
        "# print(weights_input_hidden)\n",
        "# print(weights_hidden_output)\n",
        "\n",
        "test_error = np.sum(np.square(y - test2(weights_input_hidden, weights_hidden_output, X)))\n",
        "print(\"Test error:\", \"{:.5f}\".format(test_error))\n",
        "\n",
        "print(\"Predictions on test data:\")\n",
        "print(test1(weights_input_hidden, weights_hidden_output, np.array([X[0]])))"
      ],
      "metadata": {
        "id": "Zfa45ry9Cwid",
        "outputId": "228af7d8-edbf-4727-8e50-c4546cf93e22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best coefficients: 0 0 -1 0 1\n",
            "Test error: 0.00071\n",
            "Predictions on test data:\n",
            "[[0.00059493 0.00554038 0.00061302 0.00722482]]\n"
          ]
        }
      ]
    }
  ]
}